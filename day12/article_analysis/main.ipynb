{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ByiH_Y2n3nC",
        "outputId": "ceff8ea5-1fcb-4d21-ede7-9383b81db5e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script started...\n",
            "Loaded BASE URL: https://aimodels.jadeglobal.com:8082/ollama/api\n",
            "Using MODEL: llama3.1:8b\n",
            "Starting program...\n",
            "\n",
            "Checking API connectivity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aimodels.jadeglobal.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API is reachable.\n",
            "Calling LLM API...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'aimodels.jadeglobal.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ API ERROR: 405 Client Error: Method Not Allowed for url: https://aimodels.jadeglobal.com:8082/ollama/api/generate\n",
            "\n",
            "Execution failed: 405 Client Error: Method Not Allowed for url: https://aimodels.jadeglobal.com:8082/ollama/api/generate\n",
            "\n",
            "Program finished.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "LLM_BASE_URL=\"https://aimodels.jadeglobal.com:8082/ollama/api\"\n",
        "LLM_MODEL=\"llama3.1:8b\"\n",
        "LLM_VERIFY_SSL=False\n",
        "LLM_TIMEOUT=120\n",
        "\n",
        "print(\"Script started...\", flush=True)\n",
        "\n",
        "# ==============================\n",
        "# Load Environment Variables\n",
        "# ==============================\n",
        "\n",
        "\n",
        "print(f\"Loaded BASE URL: {LLM_BASE_URL}\", flush=True)\n",
        "print(f\"Using MODEL: {LLM_MODEL}\", flush=True)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# API Connectivity Check\n",
        "# ==============================\n",
        "def check_api_connection():\n",
        "    try:\n",
        "        print(\"Checking API connectivity...\", flush=True)\n",
        "        response = requests.get(\n",
        "            LLM_BASE_URL,\n",
        "            verify=LLM_VERIFY_SSL,\n",
        "            timeout=5\n",
        "        )\n",
        "        print(\"API is reachable.\", flush=True)\n",
        "        return True\n",
        "    except requests.exceptions.RequestException:\n",
        "        print(\"❌ API NOT RESPONDING\", flush=True)\n",
        "        return False\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Prompt Builder\n",
        "# ==============================\n",
        "def build_prompt(article: str) -> str:\n",
        "    return f\"\"\"\n",
        "Return ONLY valid JSON:\n",
        "\n",
        "{{\n",
        "  \"summary\": \"string (max 150 words)\",\n",
        "  \"important_points\": [\"string\"],\n",
        "  \"key_themes\": [\"string\"],\n",
        "  \"target_audience\": \"string\"\n",
        "}}\n",
        "\n",
        "Article:\n",
        "\\\"\\\"\\\"\n",
        "{article}\n",
        "\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# LLM API Call\n",
        "# ==============================\n",
        "def call_llm(prompt: str) -> str:\n",
        "    url = f\"{LLM_BASE_URL}/generate\"\n",
        "\n",
        "    payload = {\n",
        "        \"model\": LLM_MODEL,\n",
        "        \"prompt\": prompt,\n",
        "        \"stream\": False\n",
        "    }\n",
        "\n",
        "    print(\"Calling LLM API...\", flush=True)\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            url,\n",
        "            json=payload,\n",
        "            verify=LLM_VERIFY_SSL,\n",
        "            timeout=LLM_TIMEOUT\n",
        "        )\n",
        "\n",
        "        response.raise_for_status()\n",
        "        print(\"API responded successfully.\", flush=True)\n",
        "\n",
        "        return response.json().get(\"response\", \"\")\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        print(\"❌ API TIMEOUT - Not Responding\", flush=True)\n",
        "        raise Exception(\"API Timeout\")\n",
        "\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"❌ CONNECTION ERROR - API NOT RESPONDING\", flush=True)\n",
        "        raise Exception(\"Connection Error\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(\"❌ API ERROR:\", str(e), flush=True)\n",
        "        raise\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Main\n",
        "# ==============================\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Starting program...\\n\", flush=True)\n",
        "\n",
        "    # Check API first\n",
        "    if not check_api_connection():\n",
        "        print(\"\\nStopping execution because API is not reachable.\", flush=True)\n",
        "        exit()\n",
        "\n",
        "    sample_article = \"\"\"\n",
        "    Artificial intelligence is transforming industries by automating tasks,\n",
        "    improving decision-making, and enabling predictive analytics.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        prompt = build_prompt(sample_article)\n",
        "        result = call_llm(prompt)\n",
        "\n",
        "        print(\"\\nRaw LLM Output:\\n\", flush=True)\n",
        "        print(result, flush=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"\\nExecution failed:\", str(e), flush=True)\n",
        "\n",
        "    print(\"\\nProgram finished.\", flush=True)"
      ]
    }
  ]
}